temp_comp_holt = window(maxtemp, start = 1990)
temp_actual = window(maxtemp, start = 1990)
points(temp_actual, type = "o")
debugSource('C:/Users/David/Google Drive/Masters/Summer 2020/DS 6306 - Doing Data Science/Unit 11/Unit 11 - David Wei.R')
fit_holt_linear = holt(temp, alpha = .8, beta = .2, damped = TRUE, initial = "optimal", h = 11)
# Holt dampened Exponential Model
fit_holt_exp = holt(temp, alpha = .8, beta = .2, damped = TRUE, initial = "optimal", exponential = TRUE, h = 11)
q
library(fpp2)
data(maxtemp) #1971-2016
temp <- window(maxtemp, start=1990, end=2010)
plot(temp,ylab = "Max Temperature", xlab = "Year", main = "Maximum Annual Temperatures")
# fitting exponential smoothing forecast model for up to 8 years
temp_fit1 = ses(temp, initial = "optimal",alpha = .2,h = 11)
temp_fit2 = ses(temp, initial = "optimal",alpha = .6, h = 11)
temp_fit3 = ses(temp, h = 11) #defaults
plot(temp,ylab = "Max Temperature", xlab = "Year", main = "Max Annual Temp (SES)")
# fitting exponential smoothing forecast model for up to 8 years
temp_fit1 = ses(temp, initial = "optimal",alpha = .2,h = 11)
temp_fit2 = ses(temp, initial = "optimal",alpha = .6, h = 11)
temp_fit3 = ses(temp, h = 11) #defaults
# choosing best model based on model accuracy metrics
accuracy(temp_fit1, maxtemp)
accuracy(temp_fit2, maxtemp)
accuracy(temp_fit3, maxtemp)
plot(temp,ylab = "Max Temperatures", xlab = "Year", type = "o", xlim = c(1990, 2021),ylim = c(35,50), main = "Max Annual Temp (SES)")
#Plot the estimated values from the models .. the "fitted" values are the training values.
lines(fitted(temp_fit1), col = "blue", type = "o")
lines(fitted(temp_fit2), col = "red", type = "o")
lines(fitted(temp_fit3), col = "green", type = "o")
# the  $mean values are the forecasts.
lines(temp_fit1$mean, col = "blue", type = "o")
lines(temp_fit2$mean, col = "red", type = "o")
lines(temp_fit3$mean, col = "green", type = "o")
legend("topleft", lty=1, col=c(1, "blue", "red", "green"), c("original", expression(alpha==0.2), expression(alpha==.6), expression(alpha==.89)), pch=1)
# These are the actual values!  Compare visually with the forecasts!
temp_comp = window(maxtemp, start = 1990)
points(temp_comp, type = "o")
# Compare the forecasts with the actual values with various fit metrics.
accuracy(temp_fit1, temp_comp)
accuracy(temp_fit2, temp_comp)
accuracy(temp_fit3, temp_comp)
temp_fit1$model[2:3]
temp_fit2$model[2:3]
temp_fit3$model[2:3]
accuracy(temp_fit1, temp_comp)
accuracy(temp_fit2, temp_comp)
accuracy(temp_fit3, temp_comp)
accuracy(temp_fit1, maxtemp)
accuracy(temp_fit2, maxtemp)
accuracy(temp_fit3, maxtemp)
fit_holt_linear = holt(temp, alpha = .8, beta = .2, damped = TRUE, initial = "optimal", h = 11)
fit_holt_exp = holt(temp, alpha = .8, beta = .2, damped = TRUE, initial = "optimal", exponential = TRUE, h = 11)
# estimated values using linear trend
fitted(fit_holt_linear)
# forecasted values usign linear trend
fit_holt_linear$mean
# estimated values using exponential trend
fitted(fit_holt_exp)
# forecasted values usign exponential trend
fit_holt_exp$mean
plot(temp,ylab = "Max Temperatures", xlab = "Year", type = "o", xlim = c(1990, 2021),ylim = c(35,50), main = "Max Annual Temp (Holt)")
lines(fitted(fit_holt_linear), col = "blue", type= "o")
lines(fit_holt_linear$mean,col = "blue", type= "o")
lines(fitted(fit_hold_exp), col = "green", type= "o")
lines(fit_hold_exp$mean,col = "green", type= "o")
# Holt's dampened Linear Trend Model for AUS AIR
fit_holt_linear = holt(temp, alpha = .8, beta = .2, damped = TRUE, initial = "optimal", h = 11)
# Holt dampened Exponential Model
fit_holt_exp = holt(temp, alpha = .8, beta = .2, damped = TRUE, initial = "optimal", exponential = TRUE, h = 11)
# estimated values using linear trend
fitted(fit_holt_linear)
# forecasted values usign linear trend
fit_holt_linear$mean
# estimated values using exponential trend
fitted(fit_holt_exp)
# forecasted values usign exponential trend
fit_holt_exp$mean
plot(temp,ylab = "Max Temperatures", xlab = "Year", type = "o", xlim = c(1990, 2021),ylim = c(35,50), main = "Max Annual Temp (Holt)")
# Plot the fitted value (estimated from triaining data)
lines(fitted(fit_holt_linear), col = "blue", type= "o")
# Plot the forecasts
lines(fit_holt_linear$mean,col = "blue", type= "o")
# Plot the fitted value (estimated from triaining data)
lines(fitted(fit_hold_exp), col = "green", type= "o")
#Plot the forecasts
lines(fit_hold_exp$mean,col = "green", type= "o")
# Plot the fitted value (estimated from triaining data)
lines(fitted(fit_holt_exp), col = "green", type= "o")
#Plot the forecasts
lines(fit_holt_exp$mean,col = "green", type= "o")
# with implicit Test set... it figures out by the time which are training and which are test.
accuracy(fit_holt_linear, maxtemp)
accuracy(fit_holt_exp, maxtemp)
#with explicit Test set ... (same output)
temp_comp_holt = window(maxtemp, start = 1990)
accuracy(fit_holt, temp_comp_holt)
accuracy(fit_hold_exp, temp_comp_holt)
#Add the actual values to visually compare forecasts to actual values
temp_actual = window(maxtemp, start = 1990)
points(temp_actual, type = "o")`
#Add the actual values to visually compare forecasts to actual values
temp_actual = window(maxtemp, start = 1990)
points(temp_actual, type = "o")`
temp_actual = window(maxtemp, start = 1990)
points(temp_actual, type = "o")
legend("topleft", lty=1, col=c(1, "blue", "red", "green"), c("original", expression("Linear"), expression("Exponential")), pch=1)
fit_holt_linear$model[2:3]
legend("topleft", lty=1, col=c(1, "blue", "green"), c("original", expression("Linear"), expression("Exponential")), pch=1)
plot(temp,ylab = "Max Temperatures", xlab = "Year", type = "o", xlim = c(1990, 2021),ylim = c(35,50), main = "Max Annual Temp (Holt)")
# Plot the fitted value (estimated from triaining data)
lines(fitted(fit_holt_linear), col = "blue", type= "o")
# Plot the forecasts
lines(fit_holt_linear$mean,col = "blue", type= "o")
# Plot the fitted value (estimated from triaining data)
lines(fitted(fit_holt_exp), col = "green", type= "o")
#Plot the forecasts
lines(fit_holt_exp$mean,col = "green", type= "o")
legend("topleft", lty=1, col=c(1, "blue", "green"), c("original", expression("Linear"), expression("Exponential")), pch=1)
fit_holt_linear$model[2:3]
fit_holt_exp$model[2:3]
#with explicit Test set ... (same output)
temp_comp_holt = window(maxtemp, start = 1990)
accuracy(fit_holt, temp_comp_holt)
accuracy(fit_hold_exp, temp_comp_holt)
#with explicit Test set ... (same output)
temp_comp_holt = window(maxtemp, start = 1990)
accuracy(fit_holt_linear, temp_comp_holt)
accuracy(fit_holt_exp, temp_comp_holt)
#with explicit Test set ... (same output)
temp_comp_holt = window(maxtemp, start = 1990)
accuracy(fit_holt_linear, temp_comp_holt)
accuracy(fit_holt_exp, temp_comp_holt)
#Add the actual values to visually compare forecasts to actual values
temp_actual = window(maxtemp, start = 1990)
points(temp_actual, type = "o")
help(maxtemp)
library(fpp)
data(ausair)
air = window(ausair, start = 1990, end = 2004)
plot(air,ylab = "Airline Passegners", xlab = "Year", main = "Airline Passengers")
fit1 = ses(air, initial = "simple",alpha = .2,h = 3)
fit2 = ses(air, initial = "simple",alpha = .6, h = 3)
fit3 = ses(air, h = 3) #defaults
accuracy(fit1, ausair)
accuracy(fit2, ausair)
accuracy(fit3, ausair)
plot(air,ylab = "Airline Passegners", xlab = "Year", type = "o", xlim = c(1990, 2008),ylim = c(15,50), main = "Airline Passengers")
#Plot the estimated values from the models .. the "fitted" values are the training values.
lines(fitted(fit1), col = "blue", type = "o")
lines(fitted(fit2), col = "red", type = "o")
lines(fitted(fit3), col = "green", type = "o")
# the  $mean values are the forecasts.
lines(fit1$mean, col = "blue", type = "o")
lines(fit2$mean, col = "red", type = "o")
lines(fit3$mean, col = "green", type = "o")
# These are the actual values!  Compare visually with the forecasts!
air2008 = window(ausair, start = 1990, end = 2007)
points(air2008, type = "o")
# Compare the forecasts with the actual values with various fit metrics.
accuracy(fit1, air2008)
accuracy(fit2, air2008)
accuracy(fit3, air2008)
library(fpp2)
data(maxtemp) #1971-2016
temp <- window(maxtemp, start=1990, end=2010)
plot(temp,ylab = "Max Temperature", xlab = "Year", main = "Max Annual Temp (SES)")
# fitting exponential smoothing forecast model for up to 8 years
temp_fit1 = ses(temp, initial = "optimal",alpha = .2,h = 11)
temp_fit2 = ses(temp, initial = "optimal",alpha = .6, h = 11)
temp_fit3 = ses(temp, h = 11) #defaults
temp_fit1
temp_fit1$model
temp_fit1 = ses(temp, initial = "simple",alpha = .2,h = 11)
temp_fit1$model
data(ausair)
ausair
install.packages(c("bestglm", "gplots", "ResourceSelection", "ROCR"))
install.packages(c("epitools", "samplesizeCMH"))
prop.test(335,411,p=.7,correct=TRUE)  #correct is the continuity correction option
vit.c<-data.frame(Supp=rep(c("Placebo","Vitamin C"),times=c(411,407)),
Cold=rep(c("Yes","No","Yes","No"),times=c(335,76,302,105)))
head(vit.c)
mymat<-table(vit.c)   # or table(vit.c$Supp,vit.c$Cold)
mymat
mymat_2<-matrix(c(76,335,105,302),2,2,byrow=T,dimnames=list(c("Placebo","Vitamin C"),c("No","Yes")))
mymat_2
chisq.test(mymat,correct=TRUE)
prop.table(mymat,margin=1)
prop.test(335,411,p=.7,correct=TRUE)  #correct is the continuity correction option
prop.test(mymat,correct=TRUE)
prop.test(mymat[c(2,1),c(2,1)],correct=TRUE)
library(epitools)
mymat<-matrix(c(76,335,105,302),2,2,byrow=T)
mymat<-matrix(c(76,335,105,302),2,2,byrow=T)
mymat
dimnames(mymat)<-list("Treatment"=c("Plac","Vit C"),"Response"=c("No","Yes"))
dimnames
mymat
mymat<-matrix(c(76,335,105,302),2,2,byrow=T)
mymat
dimnames(mymat)<-list("Treatment"=c("Plac","Vit C"),"Response"=c("No","Yes"))
mymat
#Odds Ratio Intervals
oddsratio.wald(mymat)
#Relative Risk Intervals
riskratio.wald(mymat)
library(epitools)
#Another way to format a count matrix
mymat<-matrix(c(76,335,105,302),2,2,byrow=T)
dimnames(mymat)<-list("Treatment"=c("Plac","Vit C"),"Response"=c("No","Yes"))
mymat
#Odds Ratio Intervals
oddsratio.wald(mymat)
#Relative Risk Intervals
riskratio.wald(mymat)
library(epitools)
#Another way to format a count matrix
mymat<-matrix(c(76,335,105,302),2,2,byrow=T)
mymat
dimnames(mymat)<-list("Treatment"=c("Plac","Vit C"),"Response"=c("No","Yes"))
mymat
#Odds Ratio Intervals
oddsratio.wald(mymat)
mymat
oddsratio.wald(mymat, rev="rows") #
oddsratio.wald(mymat, rev="columns") # results in placebo(N)/vitamin(Y)
oddsratio.wald(mymat) # results in placebo(N)/vitamin(Y)
oddsratio.wald(mymat, rev="rows") # results in placebo(Y)/Vitamin(N)
oddsratio.wald(mymat, rev="columns") # results in placebo(N)/vitamin(Y)
riskratio.wald(mymat)
riskratio.wald(mymat)
riskratio.wald(mymat, rev="rows")
riskratio.wald(mymat, rev="columns")
breast_cancer_df <-matrix(c(330,658,204,386),2,2,byrow=T)
breast_cancer_df
dimnames(breast_cancer_df)<-list("Case Type"=c("< 4 Drinks/week","> 4 Drink/week"),"Response"=c("Cases","Controls"))
breast_cancer_df
oddsratio.wald(breast_cancer_df) # results in placebo(N)/vitamin(Y)
oddsratio.wald(breast_cancer_df, rev="rows") # results in placebo(Y)/Vitamin(N)
oddsratio.wald(breast_cancer_df, rev="columns") # results in placebo(N)/vitamin(Y)
riskratio.wald(mymat)
riskratio.wald(mymat, rev="rows")
riskratio.wald(mymat, rev="columns")
oddsratio.wald(breast_cancer_df, rev="rows") # results in placebo(Y)/Vitamin(N)
oddsratio.wald(breast_cancer_df, rev="columns") # results in placebo(N)/vitamin(Y)
oddsratio.wald(breast_cancer_df) # results in placebo(N)/vitamin(Y)
oddsratio.wald(breast_cancer_df, rev="rows") # results in placebo(Y)/Vitamin(N)
oddsratio.wald(breast_cancer_df, rev="columns") # results in placebo(N)/vitamin(Y)
riskratio.wald(mymat, rev="columns")
riskratio.wald(mymat)
riskratio.wald(mymat, rev="rows")
riskratio.wald(mymat, rev="columns")
#Relative Risk Intervals
riskratio.wald(breast_cancer_df)
riskratio.wald(breast_cancer_df, rev="rows")
riskratio.wald(breast_cancer_df, rev="columns")
oddsratio.wald(breast_cancer_df) # results in placebo(N)/vitamin(Y)
riskratio.wald(mymat, rev="columns")
install.packages("aws.s3")
library(tidyr)
library(dplyr)
library(ggplot2)
wd <- "C:/Users/David/Google Drive/Code & Programming/GitHub/MSDS_6372_Applied-Statistics_Project_2/UCI_Bank_Marketing_Classification_Model/Data Files/bank-additional-full.csv"
setwd(wd)
library(tidyr)
library(dplyr)
library(ggplot2)
library(tidyverse)
setwd("C:/Users/David/Google Drive/Code & Programming/GitHub/MSDS_6372_Applied-Statistics_Project_2/UCI_Bank_Marketing_Classification_Model/Data Files/")
df <- read.csv("bank-additional-full.csv", header=TRUE, sep=";")
head(df, 5)
df <- df %>% rename(clnt.subcr = `y`)
df$clnt.subcr <- factor(df$clnt.subcr)
# finding which columns in df are categorical
cat_class <- as.data.frame(sapply(df, class))
cat_class
# converting all "unknown" values back to NA
df_stg <- df
df_stg[df_stg=="unknown"] <- NA
vis_miss(df_stg) + xlab("Data Columns")
vis_miss(df_stg) + xlab("Data Columns")
library(naniar)
vis_miss(df_stg) + xlab("Data Columns")
# filtering out all NA values from dataset
df_stg <- df_stg %>% filter(!is.na(job) & !is.na(marital) & !is.na(education) & !is.na(default)
& !is.na(housing) & !is.na(loan) & !is.na(contact))
nrow(df_stg)
nrow(df)
table(df_stg$clnt.subcr)
View(df)
nrow(df)
df$ID <- seq.int(nrow(df))
View(df)
df <- df[c("ID", everything())]
df <- select(ID, everything())
df$ID <- seq.int(nrow(df))
df <- select(ID, everything())
str(df)
df <- df %>% select(ID, everything())
str(df)
View(df)
cat_types <- c(3,4,5,6,7,8,9,10,11,16)
for(i in cat_types){
print(colnames(df[i]))
print(df %>% count(df[,i]))
}
# converting all "unknown" values back to NA
df_stg <- df
df_stg[df_stg=="unknown"] <- NA
vis_miss(df_stg) + xlab("Data Columns")
vis_miss(df_stg) + xlab("Data Columns")
vis_miss(df_stg, warn_large_data = FALSE) + xlab("Data Columns")
df_stg <- df_stg %>% filter(!is.na(job) & !is.na(marital) & !is.na(education) & !is.na(default)
& !is.na(housing) & !is.na(loan) & !is.na(contact))
# checking all missing variables filtered out
vis_miss(df_stg) + xlab("Data Columns")
nrow(df_stg)
nrow(df)
table(df_stg$clnt.subcr)
df_cat_num <- df_stg
cat_columns <- c(1,3,4,5,6,7,8,9,10,11,16)
df_cat_short <- data.frame(df_cat[, cat_columns])
df_cat <- df_stg
for(i in cat_types){
df_cat[, i] <- factor(df_cat[,i])
x <- paste(colnames(df_cat[i]),"desc", sep="_")
colnames(df_cat)[i] <- paste(x)
}
str(df_stg)
str(df_cat)
cat_columns <- c(1,3,4,5,6,7,8,9,10,11,16)
df_cat_short <- data.frame(df_cat[, cat_columns])
str(df_cat_short)
df_cat_num <- df_stg
for(i in cat_types){
df_cat_num[, i] <- as.numeric(factor(df_cat_num[,i]))
x <- paste(colnames(df_cat_num[i]),"ID", sep="_")
colnames(df_cat_num)[i] <- paste(x)
}
str(df_cat_num)
df_num_only <- df[, -cat_types]
str(df_num_only)
df_cat_merge <- merge(x=df_cat_num_short, y=df_cat_short, by="ID", all=TRUE)
df_cat_num_short <- data.frame(df_num[, cat_columns])
df_cat_short <- data.frame(df_cat[, cat_columns])
df_cat_num_short <- data.frame(df_cat_num[, cat_columns])
df_cat_short <- data.frame(df_cat[, cat_columns])
cat_columns <- c(1,3,4,5,6,7,8,9,10,11,16)
# 2 dfs, 1 storing all the IDs (df_cat_num_short), the other storying all the factored "descriptions" (df_cat_short)
df_cat_num_short <- data.frame(df_cat_num[, cat_columns])
df_cat_short <- data.frame(df_cat[, cat_columns])
# storying all numerical data into temp df excluding categorical types
df_num_only <- df[, -cat_types]
# joining the categorical factors (desc) with it's numerical types (IDs) then re-ordering
df_cat_merge <- merge(x=df_cat_num_short, y=df_cat_short, by="ID", all=TRUE)
str(df_cat_merge)
df_cat_merge <- df_short[c(1,2,12,3,13,4,14,5,15,6,16,7,17,8,18,9,19,10,20,11,21)]
df_cat_merge <- df_cat_merge[c(1,2,12,3,13,4,14,5,15,6,16,7,17,8,18,9,19,10,20,11,21)]
str(df_cat_merge)
df_final <- merge(x=df_cat_merge, y=df_num_only, by="ID", all=TRUE)
head(df_final, 1)
View(df_final)
setwd("C:/Users/David/Google Drive/Code & Programming/GitHub/MSDS_6372_Applied-Statistics_Project_2/UCI_Bank_Marketing_Classification_Model/Data Files/")
df <- read.csv("bank-additional-full.csv", header=TRUE, sep=";")
head(df, 5)
df <- df %>% rename(clnt.subcr = `y`)
# adding sequential ID column to all rows
df$ID <- seq.int(nrow(df))
df <- df %>% select(ID, everything())
# exploring the unique data values for all categorical variables
cat_types <- c(3,4,5,6,7,8,9,10,11,16,22)
for(i in cat_types){
print(colnames(df[i]))
print(df %>% count(df[,i]))
}
# converting all "unknown" values back to NA
df_stg <- df
df_stg[df_stg=="unknown"] <- NA
vis_miss(df_stg, warn_large_data = FALSE) + xlab("Data Columns")
# filtering out all NA values from dataset
df_stg <- df_stg %>% filter(!is.na(job) & !is.na(marital) & !is.na(education) & !is.na(default)
& !is.na(housing) & !is.na(loan) & !is.na(contact))
# validating reduction in row totals after filtering missing data
nrow(df_stg)
nrow(df)
table(df_stg$clnt.subcr)
for(i in cat_types){
print(colnames(df[i]))
print(df %>% count(df[,i]))
}
# new df storing ID and all converted categorical variables into factor types
df_cat <- df_stg
for(i in cat_types){
df_cat[, i] <- factor(df_cat[,i])
x <- paste(colnames(df_cat[i]),"desc", sep="_")
colnames(df_cat)[i] <- paste(x)
}
# create new df containing ID and all converted categorical variables into numerical types
df_cat_num <- df_stg
for(i in cat_types){
df_cat_num[, i] <- as.numeric(factor(df_cat_num[,i]))
x <- paste(colnames(df_cat_num[i]),"ID", sep="_")
colnames(df_cat_num)[i] <- paste(x)
}
cat_columns <- c(1,3,4,5,6,7,8,9,10,11,16,22)
# 2 dfs, 1 storing all the IDs (df_cat_num_short), the other storying all the factored "descriptions" (df_cat_short)
df_cat_num_short <- data.frame(df_cat_num[, cat_columns])
df_cat_short <- data.frame(df_cat[, cat_columns])
# storying all numerical data into temp df excluding categorical types
df_num_only <- df[, -cat_types]
# joining the categorical factors (desc) with it's numerical types (IDs) then re-ordering
df_cat_merge <- merge(x=df_cat_num_short, y=df_cat_short, by="ID", all.x=TRUE)
df_cat_merge <- df_cat_merge[c(1,2,12,3,13,4,14,5,15,6,16,7,17,8,18,9,19,10,20,11,21)]
View(df_cat_merge)
# joining all numerical with categorical data together as final df
df_final <- merge(x=df_cat_merge, y=df_num_only, by="ID", all.x=TRUE)
View(df_final)
nrow(df) #raw
nrow(df_stg) #filterd NA
nrow(df_final) #organized
str(df_final)
str(df_cat_merge)
setwd("C:/Users/David/Google Drive/Code & Programming/GitHub/MSDS_6372_Applied-Statistics_Project_2/UCI_Bank_Marketing_Classification_Model/Data Files/")
df <- read.csv("bank-additional-full.csv", header=TRUE, sep=";")
head(df, 5)
df <- df %>% rename(clnt.subcr = `y`)
library(naniar)
# adding sequential ID column to all rows
df$ID <- seq.int(nrow(df))
df <- df %>% select(ID, everything())
for(i in cat_types){
print(colnames(df[i]))
print(df %>% count(df[,i]))
}
str(df)
# converting all "unknown" values back to NA
df_stg <- df
df_stg[df_stg=="unknown"] <- NA
# filtering out all NA values from dataset
df_stg <- df_stg %>% filter(!is.na(job) & !is.na(marital) & !is.na(education) & !is.na(default)
& !is.na(housing) & !is.na(loan) & !is.na(contact))
table(df_stg$clnt.subcr)
# new df storing ID and all converted categorical variables into factor types
df_cat <- df_stg
for(i in cat_types){
df_cat[, i] <- factor(df_cat[,i])
x <- paste(colnames(df_cat[i]),"desc", sep="_")
colnames(df_cat)[i] <- paste(x)
}
str(df_cat)
# create new df containing ID and all converted categorical variables into numerical types
df_cat_num <- df_stg
for(i in cat_types){
df_cat_num[, i] <- as.numeric(factor(df_cat_num[,i]))
x <- paste(colnames(df_cat_num[i]),"ID", sep="_")
colnames(df_cat_num)[i] <- paste(x)
}
str(df_cat_num)
# 2 dfs, 1 storing all the IDs (df_cat_num_short), the other storying all the factored "descriptions" (df_cat_short)
df_cat_num_short <- data.frame(df_cat_num[, cat_columns])
str(df_cat_num_short)
df_cat_short <- data.frame(df_cat[, cat_columns])
str(df_cat_short)
# storying all numerical data into temp df excluding categorical types
df_num_only <- df[, -cat_types]
str(df_num_only)
# joining the categorical factors (desc) with it's numerical types (IDs) then re-ordering
df_cat_merge <- merge(x=df_cat_num_short, y=df_cat_short, by="ID", all.x=TRUE)
str(df_cat_merge)
df_cat_merge <- df_cat_merge[c(1,2,13,3,14,4,15,5,16,6,17,7,18,8,19,9,20,10,21,11,22,12,23)]
str(df_cat_merge)
# joining all numerical with categorical data together as final df
df_final <- merge(x=df_cat_merge, y=df_num_only, by="ID", all.x=TRUE)
head(df_final, 1)
View(df_final)
summary(df_final)
summary(df_num_only)
month_cap <- as.data.frame(str_to_title(df_final$month))
month_cap
df_final$month
month_cap <- as.data.frame(str_to_title(df_final$month_desc))
month_cap
str(month_cap)
head(month_cap)
month_cap <- rename(month_cap$`str_to_title(df_final$month_desc)` = month)
month_cap <- rename(month_cap$`str_to_title(df_final$month_desc)` == month)
library(stringr)
month_cap$`str_to_title(df_final$month_desc)`
month_cap <- as.data.frame(str_to_title(df_final$month_desc))
month_cap
str(month_cap)
month_cap$`str_to_title(df_final$month_desc)`
month_cap <- as.data.frame(str_to_title(df_final$month_desc))
head(month_cap, 1)
month_cap <- str_to_title(df_final$month_desc)
head(month_cap, 1
)
str(month_cap)
month_cap <- data.frame(month_cap)
str(month_cap)
head(month_cap)
month_ord <- factor(month_cap$month_cap, levels=month.abb)
month_ord %>% ggplot(aes(x=month, y=campaign)) + geom_bar(stat="identity")
month_ord
final_df$month
str(final_df)
str(df_final)
bank_df$month_cap <- str_to_title(df_final$month_desc)
df_final$month_cap <- str_to_title(df_final$month_desc)
df_final$month_cap <- factor(df_final$month_cap, levels=month.abb)
df_final %>% ggplot(aes(x=month_cap, y=campaign,fill=day_of_week_desc)) + geom_bar(stat="identity") + scale_x_discrete(limits=month.abb) + labs(title="# of Campaigns per Month by Day", x="Month", y="# of Campaigns", fill="Day of Week")

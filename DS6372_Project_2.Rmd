---
title: "DS6372-Project2"
author: "David Wei", "Anish Patel"
date: "7/23/2020"
output: html_document
---

#### Setup & General Libraries
```{r,warning=FALSE,message=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(tidyverse)

setwd("C:/Users/David/Google Drive/Code & Programming/GitHub/MSDS_6372_Applied-Statistics_Project_2/UCI_Bank_Marketing_Classification_Model/Data Files/")
df <- read.csv("bank-additional-full.csv", header=TRUE, sep=";")
str(df)
```

#### Data Tidying
```{r,warning=FALSE,message=FALSE}
# renaming response variable 'y' to 'Clnt_Subcr'
df <- df %>% rename(clnt.subcr = `y`)

library(naniar)
# verifying missing data: no missing data found
vis_miss(df) + xlab("Data Columns")

# adding sequential ID column to all rows
df$ID <- seq.int(nrow(df))
df <- df %>% select(ID, everything())

# finding which columns in df are categorical
cat_class <- as.data.frame(sapply(df, class))
cat_class

# exploring the unique data values for all categorical variables
cat_types <- c(3,4,5,6,7,8,9,10,11,16,22)
for(i in cat_types){
  print(colnames(df[i]))
  print(df %>% count(df[,i]))
}

# converting all "unknown" values back to NA
df_stg <- df
df_stg[df_stg=="unknown"] <- NA
vis_miss(df_stg, warn_large_data = FALSE) + xlab("Data Columns")

# filtering out all NA values from dataset
df_stg <- df_stg %>% filter(!is.na(job) & !is.na(marital) & !is.na(education) & !is.na(default)
                                      & !is.na(housing) & !is.na(loan) & !is.na(contact))
# checking all missing variables filtered out
vis_miss(df_stg) + xlab("Data Columns")
# validating reduction in row totals after filtering missing data
nrow(df)
nrow(df_stg) 

# # Converting all int to numeric value types
# int_types <- c(1,11,12,13,14)
# for(i in int_types){
#   df_stg[,i] <- as.numeric(df_stg[, i])
# }

# new df storing ID and all converted categorical variables into factor types
df_cat <- df_stg
for(i in cat_types){
  df_cat[, i] <- factor(df_cat[,i])
  x <- paste(colnames(df_cat[i]),"desc", sep="_")
  colnames(df_cat)[i] <- paste(x)
}

# create new df containing ID and all converted categorical variables into numerical types
df_cat_num <- df_stg
for(i in cat_types){
  df_cat_num[, i] <- as.numeric(factor(df_cat_num[,i]))
  x <- paste(colnames(df_cat_num[i]),"ID", sep="_")
  colnames(df_cat_num)[i] <- paste(x)
}

# new df storing all factored categorical values including the ID
cat_columns <- c(1,3,4,5,6,7,8,9,10,11,16,22)
# 2 dfs, 1 storing all the IDs (df_cat_num_short), the other storying all the factored "descriptions" (df_cat_short)
df_cat_num_short <- data.frame(df_cat_num[, cat_columns])
df_cat_short <- data.frame(df_cat[, cat_columns])

# storying all numerical data into temp df excluding categorical types
df_num_only <- df[, -cat_types]

# joining the categorical factors (desc) with it's numerical types (IDs) then re-ordering
df_cat_merge <- merge(x=df_cat_num_short, y=df_cat_short, by="ID", all.x=TRUE)
df_cat_merge <- df_cat_merge[c(1,2,13,3,14,4,15,5,16,6,17,7,18,8,19,9,20,10,21,11,22,12,23)]

# joining all numerical with categorical data together as final df
df_final <- merge(x=df_cat_merge, y=df_num_only, by="ID", all.x=TRUE)
head(df_final, 1)

# validating df matches all prior df stages
nrow(df) #raw
nrow(df_stg) #filterd NA
nrow(df_final) #organized, should match df_stg

# Downsampling
# Train/Test split with cleaned data
set.seed(27)
splitPerc = .70
df_index = sample(1:dim(df_final)[1],round(splitPerc * dim(df_final)[1]))
df_train = df_final[df_index,]
df_test = df_final[-df_index,]

# Train/Test data with Downsampling Applied
library(caret)
set.seed(27)
df_train_dwnsmpled <- downSample(x = df_train,y = df_train$clnt.subcr_desc)
df_test_dwnsmpled <- downSample(x = df_test,y = df_test$clnt.subcr_desc)

table(df_final$clnt.subcr_ID) #cleaned table
table(df_train_dwnsmpled$clnt.subcr_ID) #train downsampled
table(df_test_dwnsmpled$clnt.subcr_ID) #test downsampled

table(df_train$clnt.subcr_ID) #train nondownsampled
table(df_test$clnt.subcr_ID) #test nondownsample

```

## Objective 1 - Part 1 - Numerical Type Data
__As part of our EDA, we first wanted to determine if there was any multicollinearity present between any of the numeric variables. We can see from the correlation matrix below (Figure B.1) that there were a few highly correlated variables (corr > .95) such as  ‘Eurobor3m’ vs ‘Emp.var.rate’. We will look closer into any correlations higher than corr=.85 as our baseline for analysis. To start, based on our understanding of the that Emp.var.rate is the rate of cyclical employment with a lower rate indicating stabilitiy in employment and a higher rate indicating lots of job movement and with Eurobor3m being the interest rate of banks. However, though the correlation is high, the groupings of the interest rate is seemingly between low and high, without any middle. This could explain the higher correlations, but without proper distribution, dependcy will not be assumed.  __

\newline
__EDA based Reduced numerical attributes: difficult to remove based on EDA, will leave to feature selection process__
```{r,warning=FALSE,message=FALSE}
library(GGally)
library(corrplot)
#summary of all numerical variables
summary(df_num_only)

# creating correlation matrix  of numerical datatypes
corr_matrix_num <- df_train_dwnsmpled[,c(24:33)]
M <- cor(corr_matrix_num, use="pairwise.complete.obs")
corrplot(M, method = "number", order = "alphabet",number.cex=0.5)

# distributino of eurobor3m
df_train_dwnsmpled %>% ggplot(aes(x=euribor3m, fill=clnt.subcr_desc)) + geom_density()

# observing Eurobo3m vs Emp.var.rate
df_train_dwnsmpled %>% ggplot(aes(x=euribor3m, y=emp.var.rate, fill=clnt.subcr_desc)) + geom_jitter() +geom_smooth(method="lm")
df_train_dwnsmpled %>% count(df_train_dwnsmpled$euribor3m)
df_train_dwnsmpled %>% count(df_train_dwnsmpled$emp.var.rate)

# observing Eurobo3m vs Nr.Employed
df_train_dwnsmpled %>% ggplot(aes(x=euribor3m, y=nr.employed, fill=clnt.subcr_desc)) + geom_point() +geom_smooth(method="lm")
# observing Nr.employed vs Emp.var.rate
df_train_dwnsmpled %>% ggplot(aes(x=nr.employed, y=emp.var.rate, fill=clnt.subcr_desc)) + geom_point() +geom_smooth(method="lm")

# df_train_dwnsmpled %>% ggplot(aes(x=nr.employed, y=emp.var.rate, fill=clnt.subcr_desc)) + geom_point() +geom_smooth(method="lm")
df_train_dwnsmpled %>% ggplot(aes(x=nr.employed, fill=clnt.subcr_desc)) + geom_histogram()
```

### Objective 1 - Part 2 - Categorical Type Data
__We first wanted to explore if there was any relationships between the # of campaigns and the months it was run in (Figure B.2). We can see that interestingly, most of the campaigns were done during the summer months with fewer amount of contacts made to clients closer to winter months. Additionally, we can rule out the Day_of_Week variable as a potential explanatory variable as it appears there is a somewhat even distribution of calls being made throughout the week.__

\newline

__EDA based Reduced categorical attributes: Default, Day_of_Week, Loan_ID__
```{r,warning=FALSE,message=FALSE}
# conducting ANOVA on categorical types to observe differences between variables and our response factors
aov_test <- aov(clnt.subcr_ID~job_ID+marital_ID+education_ID+default_ID+loan_ID+contact_ID+month_ID+poutcome_ID, data=df_train_dwnsmpled)
summary.aov(aov_test)

# is there a relationship between # of contacts made and the month or week?
library(stringr)
df_train_dwnsmpled$month_desc <- str_to_title(df_train_dwnsmpled$month_desc)
df_train_dwnsmpled$month_desc <- factor(df_train_dwnsmpled$month_cap, levels=month.abb)
# number of campaigns run per month
df_train_dwnsmpled %>% ggplot(aes(x=month_desc, y=campaign,fill=day_of_week_desc)) + geom_bar(stat="identity") + scale_x_discrete(limits=month.abb) + labs(title="# of Campaigns per Month by Day", x="Month", y="# of Campaigns", fill="Day of Week")

# job_desc vs emp.var.rate
df_train_dwnsmpled %>% ggplot(aes(x=clnt.subcr_desc, y=duration)) + geom_boxplot()


```

### Objective 1 - Feature Selection & Logistic Regression Modeling
```{r,warning=FALSE,message=FALSE}
library(MASS)
# defining variables to exclude based on EDA (removing "_desc" attributes)
exclude_columns_EDA <- c(1,3,5,7,8,9,12,13,15,17,18,19,21,34)

# removing the EDA based attributes to both the downsampled test and train set
full_model_train <- df_train_dwnsmpled[, -exclude_columns_EDA]
full_model_test <- df_test_dwnsmpled[, -exclude_columns_EDA]
#validating column consistency
ncol(full_model_train)
ncol(full_model_test)

nrow(full_model_train)
nrow(full_model_test)

full_model <- lm(clnt.subcr_ID~., data=full_model_train[, -10])

# stepwise Model
step_model <- stepAIC(full_model, direction="both", trace=FALSE)
summary(step_model)

# Forward Model
fwd_model <- stepAIC(full_model, direction="forward", trace=FALSE)
summary(fwd_model)
# Backward Model
bck_model <- stepAIC(full_model, direction="backward", trace=FALSE)
summary(bck_model)
# LASSO model

# Logistic Regression Model
library(glmnet)
logit_model <- glm(clnt.subcr_desc~., family="binomial", data=full_model_train[, -9])
summary(logit_model)

#determing accuracy of logitic regression model
logit_pred <- predict(logit_model, newdata=full_model_test, type="response")
cutoff <- .5
logit_pred.class <- factor(ifelse(logit_pred>cutoff, "yes", "no"))

confusionMatrix(logit_pred.class, as.factor(full_model_test$clnt.subcr_desc))

# ROC curve

```

### Objective 2 - Competing Models and Model Tuning
```{r,warning=FALSE,message=FALSE}
```












